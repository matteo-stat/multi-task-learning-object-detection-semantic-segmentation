{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt, colors as pltcolors, patches\n",
    "from PIL import Image\n",
    "import ssdseglib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# global variables / objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image shape\n",
    "INPUT_IMAGE_SHAPE = (480, 640)\n",
    "\n",
    "# labels conversions\n",
    "LABEL_CODE_TO_DESC = {\n",
    "    1: 'monorail',\n",
    "    2: 'person',\n",
    "    3: 'forklift'\n",
    "}\n",
    "\n",
    "LABEL_CODE_TO_COLOR = {\n",
    "    1: 'red',\n",
    "    2: 'green',\n",
    "    3: 'blue'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# object detection\n",
    "\n",
    "object detection it's a computer vision task where the goal it's to identify and localize multiple objects within an image or a video frame.\n",
    "\n",
    "it combines two main challenges:\n",
    "\n",
    "* **classification**: it's a classification problem, where the task it's to determine the type of objects present in the image\n",
    "\n",
    "* **localization**: it's a regression problem, where the task it's to determine the location of detected objects within the image, usually providing coordinates for a bounding box around each object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ground truth data\n",
    "\n",
    "let's see some ground truth data examples for an object detection task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "data = []\n",
    "\n",
    "# train\n",
    "with open('data/train.json', 'r') as f:\n",
    "    data.extend(json.load(f))\n",
    "\n",
    "# train additional - persons\n",
    "with open('data/train-additional-persons.json', 'r') as f:\n",
    "    persons = json.load(f)\n",
    "    persons = random.sample(persons, int(len(persons)*0.8))\n",
    "    data.extend(persons)\n",
    "\n",
    "# train additional - forklifts\n",
    "with open('data/train-additional-forklifts.json', 'r') as f:\n",
    "    data.extend(json.load(f))\n",
    "\n",
    "# the training set it's small and the validation set even smaller..\n",
    "# it's so small that probably any metrics on it won't be particularly reliable \n",
    "# at this point maybe it's just better to use the validation set as additional training data\n",
    "with open('data/eval-persons-forklifts.json', 'r') as f:\n",
    "    data.extend(json.load(f))\n",
    "\n",
    "# unpack train metadata into separate lists\n",
    "path_files_images_train, path_files_masks_train, path_files_labels_boxes_train = map(list, zip(*data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 5 random samples\n",
    "for path_file_image, path_file_mask, path_files_labels_boxes in random.sample(data, 5):\n",
    "\n",
    "    # read labels and boxes\n",
    "    with open(path_files_labels_boxes, 'r') as f:\n",
    "        labels_boxes = list(csv.reader(f))\n",
    "    \n",
    "    # read image\n",
    "    image = Image.open(path_file_image)\n",
    "    image = np.array(image)\n",
    "    image = image.astype(np.int32)\n",
    "\n",
    "    # create the plot\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # plot the image\n",
    "    plt.imshow(image, vmin=0, vmax=255)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # get the current plot object\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # plot bounding boxes\n",
    "    for label, xmin, ymin, xmax, ymax in labels_boxes:\n",
    "        # type conversions\n",
    "        label = int(label)\n",
    "        xmin = float(xmin)\n",
    "        ymin = float(ymin)\n",
    "        xmax = float(xmax)\n",
    "        ymax = float(ymax)\n",
    "\n",
    "        # bounding boxes\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin + 1, ymax - ymin + 1, linewidth=1, edgecolor=LABEL_CODE_TO_COLOR[label], facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # label descriptions\n",
    "        plt.text(xmin, ymin, LABEL_CODE_TO_DESC[label], fontsize=8, color=LABEL_CODE_TO_COLOR[label], verticalalignment='top')\n",
    "\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ssd - single shot multibox detector\n",
    "\n",
    "in computer vision there are various approaches to solve object detection problems, one of them it's the single shot multiBox detector (ssd).\n",
    "\n",
    "ssd is an object detection framework that aims to simultaneously predict object classes and bounding box locations in a single pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### default grids\n",
    "\n",
    "the basic idea of ssd it's fairly simple: let's imagine to divide an input image into a grid multiple times, each time using a complete different grid!\n",
    "\n",
    "why not only one? don't worry, i'll explain it very soon :smiley:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create default bounding boxes\n",
    "default_bounding_boxes = ssdseglib.boxes.DefaultBoundingBoxes(\n",
    "    feature_maps_shapes=((30, 40), (15, 20), (8, 10), (4, 5)),\n",
    "    centers_padding_from_borders_percentage=(0.025, 0.05, 0.075, 0.1),\n",
    "    additional_square_box=True,\n",
    ")\n",
    "\n",
    "# scale default bounding boxes to image shape\n",
    "default_bounding_boxes.rescale_boxes_coordinates(image_shape=INPUT_IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subplots and set figure size\n",
    "fig_size_width = 11\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, constrained_layout=True)\n",
    "fig.set_size_inches(fig_size_width, int(fig_size_width / (INPUT_IMAGE_SHAPE[1] / INPUT_IMAGE_SHAPE[0])))\n",
    "\n",
    "# set aspect ratio for each subplot\n",
    "for ax in axes.flat:\n",
    "    ax.set_aspect('equal')\n",
    "axes = axes.flatten()\n",
    "\n",
    "# pick a different color for each grid\n",
    "colors = list(pltcolors.BASE_COLORS.values())[:len(default_bounding_boxes.feature_maps_shapes)]\n",
    "\n",
    "# get boxes centroids coordinates for each feature map and plot the boxes centers\n",
    "i = 0\n",
    "for boxes_default, color in zip(default_bounding_boxes.get_boxes_coordinates_centroids('feature-maps'), colors):\n",
    "\n",
    "    # reshape\n",
    "    boxes_default = boxes_default.reshape((-1, boxes_default.shape[-1]))\n",
    "\n",
    "    # set plot axes limits and title\n",
    "    axes[i].set_xlim(0, INPUT_IMAGE_SHAPE[1])\n",
    "    axes[i].set_ylim(0, INPUT_IMAGE_SHAPE[0])\n",
    "    axes[i].set_title(f'feature map {i +1} - boxes grid')\n",
    "\n",
    "    # plot centers\n",
    "    axes[i].scatter(x=boxes_default[:, 0], y=boxes_default[:, 1], color=color, marker='o', s=1)\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "# hide the last axis\n",
    "if len(axes) > len(default_bounding_boxes.feature_maps_shapes):\n",
    "    axes[-1].axis('off')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### default bounding boxes\n",
    "\n",
    "before explaining why multiple grids, let's keep focusing on the basic idea behind ssd.\n",
    "\n",
    "rembember that we just divided the input image into different grids.\n",
    "\n",
    "now try to think about a set of N boxes (or rectangles if you prefer), each one slightly different, with different aspect ratios, weigths, heights...\n",
    "\n",
    "let's imagine to place this set of boxes on each point of the grids, so that boxes centers corresponds to grids points.\n",
    "\n",
    "this is exactly the concept of default bounding boxes proposed by ssd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subplots and set figure size\n",
    "fig_size_width = 11\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, constrained_layout=True)\n",
    "fig.set_size_inches(fig_size_width, int(fig_size_width / (INPUT_IMAGE_SHAPE[1] / INPUT_IMAGE_SHAPE[0])))\n",
    "\n",
    "# set aspect ratio for each subplot\n",
    "for ax in axes.flat:\n",
    "    ax.set_aspect('equal')\n",
    "axes = axes.flatten()\n",
    "\n",
    "# pick a different color for each grid\n",
    "colors = list(pltcolors.BASE_COLORS.values())[:len(default_bounding_boxes.feature_maps_shapes)]\n",
    "\n",
    "# get boxes corners coordinates for each feature map and plot the boxes\n",
    "i = 0\n",
    "for boxes_default, color in zip(default_bounding_boxes.get_boxes_coordinates_corners('feature-maps'), colors):\n",
    "   \n",
    "    # extract boxes around the center of the feature map\n",
    "    feat_map_center_x = boxes_default.shape[1] // 2\n",
    "    feat_map_center_y = boxes_default.shape[0] // 2\n",
    "    boxes_default = boxes_default[feat_map_center_y, feat_map_center_x, :, :]\n",
    "\n",
    "    # set plot axes limits and title\n",
    "    axes[i].set_xlim(0, INPUT_IMAGE_SHAPE[1])\n",
    "    axes[i].set_ylim(0, INPUT_IMAGE_SHAPE[0])\n",
    "    axes[i].set_title(f'feature map {i +1} - boxes grid')\n",
    "\n",
    "    # plot boxes\n",
    "    for xmin, ymin, xmax, ymax in boxes_default:\n",
    "        axes[i].add_patch(patches.Rectangle((xmin, ymin), xmax - xmin + 1, ymax - ymin + 1, linewidth=1, edgecolor=color, facecolor='none'))\n",
    "                \n",
    "    i+=1\n",
    "\n",
    "# hide the last axis\n",
    "if len(axes) > len(default_bounding_boxes.feature_maps_shapes):\n",
    "    axes[-1].axis('off')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum it up\n",
    "\n",
    "ssd framework for object detection propose to divide the input image with K different grids and to place on each grids point a set of N boxes.\n",
    "\n",
    "this operation will create a set of default bounding boxes, often called also anchor boxes.\n",
    "\n",
    "they are useful because ideally a neural network can leverage on this set of pre-defined boxes instead of figuring out from scratch where the objects are in the image.\n",
    "\n",
    "basically ssd propose to train a neural network so that:\n",
    "\n",
    "* it will predict what type of object it's inside each default bounding box\n",
    "* it will predict how far a default bounding box it's from the real bounding box\n",
    "\n",
    "to achieve that, we need to encode properly the ground truth data, a process that consists in calculating the distance/offsets between the default bounding boxes and a ground truth box."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
