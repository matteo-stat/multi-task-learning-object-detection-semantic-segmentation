{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt, patches\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import ssdseglib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# global variables / objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "INPUT_IMAGE_SHAPE = (480, 640)\n",
    "BATCH_SIZE = 16\n",
    "SEED = 1993\n",
    "\n",
    "# labels conversions\n",
    "LABEL_CODE_TO_DESC = {\n",
    "    1: 'monorail',\n",
    "    2: 'person',\n",
    "    3: 'forklift'\n",
    "}\n",
    "LABEL_CODE_TO_COLOR = {\n",
    "    1: 'red',\n",
    "    2: 'green',\n",
    "    3: 'blue'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# default bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create default bounding boxes\n",
    "boxes_default = ssdseglib.boxes.DefaultBoundingBoxes(\n",
    "    feature_maps_shapes=((30, 40), (15, 20), (8, 10), (4, 5)),\n",
    "    centers_padding_from_borders_percentage=0.025,\n",
    "    boxes_scales=(0.15, 1.0),\n",
    "    additional_square_box=True,  \n",
    ")\n",
    "\n",
    "# scale default bounding boxes to image shape\n",
    "boxes_default.rescale_boxes_coordinates(image_shape=INPUT_IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data reader encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data reader encoder\n",
    "data_reader_encoder = ssdseglib.datacoder.DataEncoderDecoder(\n",
    "    num_classes=4,\n",
    "    image_shape=INPUT_IMAGE_SHAPE,\n",
    "    xmin_boxes_default=boxes_default.get_boxes_coordinates_xmin(coordinates_style='ssd'),\n",
    "    ymin_boxes_default=boxes_default.get_boxes_coordinates_ymin(coordinates_style='ssd'),\n",
    "    xmax_boxes_default=boxes_default.get_boxes_coordinates_xmax(coordinates_style='ssd'),\n",
    "    ymax_boxes_default=boxes_default.get_boxes_coordinates_ymax(coordinates_style='ssd'),\n",
    "    iou_threshold=0.5,\n",
    "    standard_deviations_centroids_offsets=(0.1, 0.1, 0.2, 0.2),\n",
    "    augmentation_horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check read, encoding and decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data\n",
    "data = []\n",
    "\n",
    "with open('data/train.json', 'r') as f:\n",
    "    data.extend(json.load(f))\n",
    "\n",
    "with open('data/train-additional-persons.json', 'r') as f:\n",
    "    data.extend(json.load(f))\n",
    "\n",
    "with open('data/train-additional-forklifts.json', 'r') as f:\n",
    "    data.extend(json.load(f))\n",
    "\n",
    "path_images_train, path_masks_train, path_labels_boxes_train = map(list, zip(*data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample some data randomly\n",
    "random_sample = random.sample(range(len(path_images_train)), k=100)\n",
    "path_images_train = np.array(path_images_train)[random_sample]\n",
    "path_masks_train = np.array(path_masks_train)[random_sample]\n",
    "path_labels_boxes_train = np.array(path_labels_boxes_train)[random_sample]\n",
    "\n",
    "# tensorflow train dataset pipeline\n",
    "ds_train = (\n",
    "    tf.data.Dataset.from_tensor_slices((path_images_train, path_masks_train, path_labels_boxes_train))\n",
    "    .map(data_reader_encoder.read_and_encode, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(batch_size=BATCH_SIZE)\n",
    "    .map(ssdseglib.datacoder.augmentation_rgb_channels, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# sample counter (used for plot ground truth bounding boxes)\n",
    "i = 0\n",
    "\n",
    "# figure size\n",
    "fig_size_width = 11\n",
    "\n",
    "# check if data it's read, encoded and decoded properly\n",
    "for image_batch, targets_batch in ds_train.take(1):\n",
    "    for image_sample, mask_sample, labels_sample, boxes_sample in zip(image_batch, targets_batch['output-mask'], targets_batch['output-labels'], targets_batch['output-boxes']):\n",
    "        \n",
    "        # read labels boxes from csv file, this is for ground truth\n",
    "        with open(path_labels_boxes_train[i], 'r') as f:\n",
    "            labels_boxes = list(csv.reader(f))\n",
    "\n",
    "        # create the needed subplots and set figure size\n",
    "        fig, ((ax1, ax3), (ax2, ax4)) = plt.subplots(nrows=2, ncols=2,  constrained_layout=True)        \n",
    "        fig.set_size_inches(fig_size_width, int(fig_size_width / (INPUT_IMAGE_SHAPE[1] / INPUT_IMAGE_SHAPE[0])))\n",
    "        \n",
    "        # ------------------------------------------------------------------------------------------------------------------\n",
    "        # ground truth - bounding boxes\n",
    "        # ------------------------------------------------------------------------------------------------------------------\n",
    "        # this is useful to see the original data, untouched by the tensorflow data pipeline\n",
    "\n",
    "        # read ground truth image        \n",
    "        image = Image.open(path_images_train[i])\n",
    "        image = np.array(image)\n",
    "        image = image.astype(np.int32)\n",
    "\n",
    "        # setup the subplot\n",
    "        ax1.set_aspect('equal')\n",
    "        ax1.imshow(image, vmin=0, vmax=255)\n",
    "        ax1.set_axis_off()\n",
    "        ax1.set_title(f'ground truth data ({Path(path_images_train[i]).name})')\n",
    "\n",
    "        # plot ground truth boxes\n",
    "        for label, xmin, ymin, xmax, ymax in labels_boxes:\n",
    "            label = int(label)\n",
    "            xmin = float(xmin)\n",
    "            ymin = float(ymin)\n",
    "            xmax = float(xmax)\n",
    "            ymax = float(ymax)        \n",
    "            rect = patches.Rectangle((xmin, ymin), xmax - xmin + 1, ymax - ymin + 1, linewidth=1, edgecolor=LABEL_CODE_TO_COLOR[label], facecolor='none')\n",
    "            ax1.add_patch(rect)\n",
    "            ax1.text(xmin, ymin, LABEL_CODE_TO_DESC[label], fontsize=8, color=LABEL_CODE_TO_COLOR[label], verticalalignment='top')        \n",
    "\n",
    "        # ------------------------------------------------------------------------------------------------------------------\n",
    "        # encoded masks - semantic segmentation mask\n",
    "        # ------------------------------------------------------------------------------------------------------------------\n",
    "        # remove the background class and keep the other 3 classes on rgb channels\n",
    "        mask_sample = tf.slice(mask_sample, begin=[0, 0, 1], size=[-1, -1, 3])\n",
    "\n",
    "        # setup the subplot\n",
    "        ax2.set_aspect('equal')\n",
    "        ax2.imshow(mask_sample, vmin=0.0, vmax=1.0)\n",
    "        ax2.set_axis_off()\n",
    "        ax2.set_title('segmentation mask after encoding')\n",
    "\n",
    "        # ------------------------------------------------------------------------------------------------------------------\n",
    "        # decoded boxes - show the matched boxes after the encoding decoding process\n",
    "        # ------------------------------------------------------------------------------------------------------------------\n",
    "        # this subplot it's very important because it can easily show if the encoding decoding process was done properly or not\n",
    "        # if some default bounding boxes were matched with ground truth boxes and properly encoded,\n",
    "        # then through decoding process we should get back coordinates for the original ground truth boxes\n",
    "        # basically the decoded boxes should match the ground truth ones\n",
    "\n",
    "        # use the one-hot-encoded labels to create a boolean vector for select items not related to background class\n",
    "        not_background = tf.math.equal(labels_sample[:, 0], 0.0)\n",
    "\n",
    "        # keep only decoded boxes not related to background class\n",
    "        decoded_boxes = data_reader_encoder.decode_to_corners(offsets_centroids=boxes_sample)\n",
    "        decoded_boxes_sample_not_background = tf.boolean_mask(\n",
    "            tensor=decoded_boxes,\n",
    "            mask=not_background,\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "        # keep only corresponding labels not related to background class\n",
    "        valid_labels_sample = tf.boolean_mask(\n",
    "            tensor=labels_sample,\n",
    "            mask=not_background,\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "        # setup subplot\n",
    "        ax3.set_aspect('equal')\n",
    "        ax3.imshow(tf.cast(image_sample, tf.int32), vmin=0, vmax=255)\n",
    "        ax3.set_axis_off()\n",
    "        ax3.set_title(f'decoded offsets after encoding ({decoded_boxes_sample_not_background.shape[0]} boxes)')\n",
    "\n",
    "        # plot decoded boxes\n",
    "        for labels_one_hot_encoded, (xmin, ymin, xmax, ymax) in zip(valid_labels_sample, decoded_boxes_sample_not_background):\n",
    "            label = int(tf.argmax(labels_one_hot_encoded))\n",
    "            xmin = float(xmin)\n",
    "            ymin = float(ymin)\n",
    "            xmax = float(xmax)\n",
    "            ymax = float(ymax)            \n",
    "            rect = patches.Rectangle((xmin, ymin), xmax - xmin + 1, ymax - ymin + 1, linewidth=1, edgecolor=LABEL_CODE_TO_COLOR[label], facecolor='none')\n",
    "            ax3.add_patch(rect)\n",
    "            ax3.text(xmin, ymin, LABEL_CODE_TO_DESC[label], fontsize=8, color=LABEL_CODE_TO_COLOR[label], verticalalignment='top')\n",
    "\n",
    "        # ------------------------------------------------------------------------------------------------------------------\n",
    "        # default bounding boxe boxes - show the matched default bounding boxes\n",
    "        # ------------------------------------------------------------------------------------------------------------------\n",
    "        # this is just for fun :)\n",
    "\n",
    "        # keep default bounding boxes not related to background class \n",
    "        default_boxes_sample_not_background = tf.concat(\n",
    "            values=[\n",
    "                tf.expand_dims(input=tf.boolean_mask(tensor=data_reader_encoder.xmin_boxes_default, mask=not_background, axis=0), axis=1),\n",
    "                tf.expand_dims(input=tf.boolean_mask(tensor=data_reader_encoder.ymin_boxes_default, mask=not_background, axis=0), axis=1),\n",
    "                tf.expand_dims(input=tf.boolean_mask(tensor=data_reader_encoder.xmax_boxes_default, mask=not_background, axis=0), axis=1),\n",
    "                tf.expand_dims(input=tf.boolean_mask(tensor=data_reader_encoder.ymax_boxes_default, mask=not_background, axis=0), axis=1),\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # setup subplot\n",
    "        ax4.set_aspect('equal')\n",
    "        ax4.imshow(tf.cast(image_sample, tf.int32), vmin=0, vmax=255)\n",
    "        ax4.set_axis_off()\n",
    "        ax4.set_title(f'matched default boxes ({default_boxes_sample_not_background.shape[0]} boxes)')\n",
    "\n",
    "        # plot default bounding boxes\n",
    "        for labels_one_hot_encoded, (xmin, ymin, xmax, ymax) in zip(valid_labels_sample, default_boxes_sample_not_background):\n",
    "            label = int(tf.argmax(labels_one_hot_encoded))\n",
    "            xmin = float(xmin)\n",
    "            ymin = float(ymin)\n",
    "            xmax = float(xmax)\n",
    "            ymax = float(ymax)            \n",
    "            rect = patches.Rectangle((xmin, ymin), xmax - xmin + 1, ymax - ymin + 1, linewidth=1, edgecolor=LABEL_CODE_TO_COLOR[label], facecolor='none')\n",
    "            ax4.add_patch(rect)\n",
    "\n",
    "        # show the figure\n",
    "        plt.show()\n",
    "\n",
    "        # sample counter (used for plot ground truth bounding boxes)\n",
    "        i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
